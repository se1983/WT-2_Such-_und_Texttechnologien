{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mbox{Sebastian Schmid}$$\n",
    "\n",
    "$$\\mbox{s0543196}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Engine\n",
    "\n",
    "\n",
    "Zweite Belegaufgabe aus dem Fach Contentmanagement / Text- und Suchtechnologien (WT-2) an der HTW Berlin bei Herrn Prof. Dr. Zhang.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graded02.pdf\tmy_spider.log\t      __pycache__\t  stop_words.txt\r\n",
      "index.txt\tmy_spider.py\t      rank.txt\t\t  tfidf_search.txt\r\n",
      "my_spider.json\tpageranke_search.txt  SearchEngine.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "import re \n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einleitung\n",
    "\n",
    "Im Rahmen dieser Belegarbeit sollte eine einfache Suchengine implementiert werden.\n",
    "\n",
    "Dabei waren folgende Schritte abzuarbeiten:\n",
    "\n",
    "1. Implementierung eines Crawlers zur Erfassung einer Link und Textstruktur .\n",
    "1. Implementierung eines Algorithmus zur Berechnung der Pageranks.\n",
    "1. Implementierung eines Scoringverfahren nach TF-IDF\n",
    "1. Erweitern des TF-IDF Scorings mit Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"1250\"\n",
       "            src=\"./graded02.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f80b67be128>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"./graded02.pdf\", width=900, height=1250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a ) Der Crawler\n",
    "\n",
    "*Der Crawler wurde mit der Bibliothek Scrapy umgesetzt. Es wurde sich hier gegen eine Einrichtung eines Projektes und für eine Scriptbasierte Lösung entschieden.\n",
    "Um die Ausführung über das Notebook zu regeln, wurde über das MagicFlag ```%%writefile``` die Klasse in eine Datei geschrieben und der Aufruf über von Scrapy über subprocess umgesetzt.*\n",
    "\n",
    "Die Klasse HtwSpider implementiert über die Einstiegspunkte, die Extraktionsanweisungen sowie dem gewünschten Link-Verhalten den Crawler.\n",
    "\n",
    "Dabei werden der Titel, der Text und die ausgehenden Links aller Seiten gespeichert, die von den EInstiegspunkten aus eirreichbar sind.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./my_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./my_spider.py\n",
    "# %%writefile ./my_spider.py\n",
    "# %load ./my_spider.py\n",
    "\n",
    "import scrapy\n",
    "import json\n",
    "\n",
    "class HtwSpider(scrapy.Spider):\n",
    "    name = 'htw_spider'\n",
    "    \n",
    "    start_urls = [\n",
    "        'http://people.f4.htw-berlin.de/~zhangg/pages/teaching/pages/d01.html',\n",
    "        'http://people.f4.htw-berlin.de/~zhangg/pages/teaching/pages/d06.html',\n",
    "        'http://people.f4.htw-berlin.de/~zhangg/pages/teaching/pages/d08.html'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "         \n",
    "        # - Extracting the needed attributes.\n",
    "        title = response.xpath('//title/text()').extract()[0]\n",
    "        text = ' '.join([t.strip() for t in response.xpath('//body/text()').extract()]).strip()\n",
    "        hrefs =  [l.split('.')[0] for l in response.xpath('//a/@href').extract()]\n",
    "                      \n",
    "        # - Printing the extracted data for logging. \n",
    "        print(\"\\n ----DATA\\n\\n%s\\n\" % json.dumps({title : {'text': text, \n",
    "                        'refs' : hrefs }}))\n",
    "        \n",
    "        # - Yielding the extracted dataset as dict\n",
    "        yield {'title': title,\n",
    "               'text': text, \n",
    "               'refs' : hrefs }\n",
    "        # - Here we find the actual spider.\n",
    "        # - This goes through all a_hrefs and scrapes the needed data.\n",
    "        for next_page in response.xpath('//a/@href').extract():\n",
    "            if next_page is None:\n",
    "                continue\n",
    "            next_page = response.urljoin(next_page)\n",
    "            yield scrapy.Request(next_page, callback=self.parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Ausführung\n",
    "\n",
    "Die Ausführung erfolgt außerhalb des Notebooks über ```subprocess.check_output()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - Here we call the scrapy process.\n",
    "# \n",
    "# - This is needed to call this inside the notebook.\n",
    "# - Scrapy concatenates all outputs (with destroying the json)\n",
    "#   so we need to remove it first.\n",
    "!rm ./my_spider.json\n",
    "\n",
    "# - Executing the spider.\n",
    "pout = check_output('scrapy runspider my_spider.py -o my_spider.json', shell=True)\n",
    "# - Writing the output into logfile.\n",
    "with open('./my_spider.log', 'w') as logfile:\n",
    "    logfile.write(pout.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Einlesen der Daten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>refs</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d01</th>\n",
       "      <td>[d02, d03, d04]</td>\n",
       "      <td>Given a character sequence and a defined docum...</td>\n",
       "      <td>d01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d06</th>\n",
       "      <td>[d07]</td>\n",
       "      <td>In text classification, we are given a descrip...</td>\n",
       "      <td>d06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d08</th>\n",
       "      <td>[]</td>\n",
       "      <td>s is a spam page. tokens stopwords index posti...</td>\n",
       "      <td>d08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d04</th>\n",
       "      <td>[d01, d02, d03, d05]</td>\n",
       "      <td>To gain the speed benefits of indexing at retr...</td>\n",
       "      <td>d04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d03</th>\n",
       "      <td>[d04, d01, d02, d05]</td>\n",
       "      <td>For English, an alternative to making every to...</td>\n",
       "      <td>d03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d02</th>\n",
       "      <td>[d03, d04, d01, d05]</td>\n",
       "      <td>Token normalization is the process of canonica...</td>\n",
       "      <td>d02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d07</th>\n",
       "      <td>[d06]</td>\n",
       "      <td>Using a supervised learning method or learning...</td>\n",
       "      <td>d07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d05</th>\n",
       "      <td>[d04]</td>\n",
       "      <td>Index the documents that each term occurs in b...</td>\n",
       "      <td>d05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       refs  \\\n",
       "title                         \n",
       "d01         [d02, d03, d04]   \n",
       "d06                   [d07]   \n",
       "d08                      []   \n",
       "d04    [d01, d02, d03, d05]   \n",
       "d03    [d04, d01, d02, d05]   \n",
       "d02    [d03, d04, d01, d05]   \n",
       "d07                   [d06]   \n",
       "d05                   [d04]   \n",
       "\n",
       "                                                    text title  \n",
       "title                                                           \n",
       "d01    Given a character sequence and a defined docum...   d01  \n",
       "d06    In text classification, we are given a descrip...   d06  \n",
       "d08    s is a spam page. tokens stopwords index posti...   d08  \n",
       "d04    To gain the speed benefits of indexing at retr...   d04  \n",
       "d03    For English, an alternative to making every to...   d03  \n",
       "d02    Token normalization is the process of canonica...   d02  \n",
       "d07    Using a supervised learning method or learning...   d07  \n",
       "d05    Index the documents that each term occurs in b...   d05  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - Reading the Data from json into python obj-structure.-\n",
    "with open('./my_spider.json') as infile:\n",
    "    data = json.loads(''.join([line.strip() for line in infile.readlines()]))   \n",
    "    \n",
    "# - Removing all duplicates\n",
    "data = list({d['title']:d for d in data}.values())\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df.index = df['title']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)  Berechnung des Page Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition der Datenstrukturen**\n",
    "\n",
    "Um die Berechung zu vereinfachen, wurde die Datenhaltung in Form eines Graphen angeordnet.\n",
    "\n",
    "Dabei hält jeder Knoten die ein- und ausgehenden Kanten, seinen Namen und die für die Berechung benötigten Platzhalter für das Zwischenspeichern der Ergebnisse. Auf Grund der rekursiven Struktur der Berechnungen müssen die Werte bereits belegt sein.\n",
    "\n",
    "Hierbei ist es wichtig, dass die Variablen ```rank``` eine vollständige Wahrscheinlichkeitsverteilung  $\\left(\\sum n \\in N = 1\\right)$ beschreiben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Initial graph:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in</th>\n",
       "      <th>node</th>\n",
       "      <th>out</th>\n",
       "      <th>rank</th>\n",
       "      <th>rank_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[d04, d03, d02]</td>\n",
       "      <td>d01</td>\n",
       "      <td>[d02, d03, d04]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[d07]</td>\n",
       "      <td>d06</td>\n",
       "      <td>[d07]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>d08</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[d01, d03, d02, d05]</td>\n",
       "      <td>d04</td>\n",
       "      <td>[d01, d02, d03, d05]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[d01, d04, d02]</td>\n",
       "      <td>d03</td>\n",
       "      <td>[d04, d01, d02, d05]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[d01, d04, d03]</td>\n",
       "      <td>d02</td>\n",
       "      <td>[d03, d04, d01, d05]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[d06]</td>\n",
       "      <td>d07</td>\n",
       "      <td>[d06]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[d04, d03, d02]</td>\n",
       "      <td>d05</td>\n",
       "      <td>[d04]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     in node                   out   rank  rank_\n",
       "0       [d04, d03, d02]  d01       [d02, d03, d04]  0.125   1.04\n",
       "1                 [d07]  d06                 [d07]  0.125   1.04\n",
       "2                    []  d08                    []  0.125   1.04\n",
       "3  [d01, d03, d02, d05]  d04  [d01, d02, d03, d05]  0.125   1.04\n",
       "4       [d01, d04, d02]  d03  [d04, d01, d02, d05]  0.125   1.04\n",
       "5       [d01, d04, d03]  d02  [d03, d04, d01, d05]  0.125   1.04\n",
       "6                 [d06]  d07                 [d06]  0.125   1.04\n",
       "7       [d04, d03, d02]  d05                 [d04]  0.125   1.04"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = 0.04 \n",
    "N = len(data)\n",
    "t = 0.05\n",
    "d = 1-t\n",
    "\n",
    "graph = [   # - The graph of the web.\n",
    "            #     Rank' is mocked with the purpose of simplifying the calculations.\n",
    "        {\n",
    "            'node':  d['title'], \n",
    "            'out':   d['refs'], \n",
    "            'in' :   [n['title'] for n in data if d['title'] in n['refs']],\n",
    "            'rank':  1.0 / N,          # (1 / n) \\leq 1 \\forall n \\in \\mathbb{N}\n",
    "            'rank_': 1.0 + delta       # mocking rank_\n",
    "        } \n",
    "    for d in data ]\n",
    "\n",
    "print('\\n\\nInitial graph:\\n')\n",
    "pd.DataFrame.from_dict(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition des Algorithmus zur Berechung des PageRank eines Knoten**\n",
    "\n",
    "\n",
    "$$\n",
    "r_{k+1}(p_i) = d \\cdot \\left( \\sum_{pj \\in B_{p_i}}   \\frac{r_k(pj)}{|pj|}  + \\sum_{pj,\\,|pj|=0}  \\frac{r_k(p_j)}{N} \\right) + \\frac{t}{N}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - Get the amount of all outgoing refs of pj\n",
    "out_len = lambda pj: [len(page['out']) for page in graph if page['node'] == pj][0]\n",
    "\n",
    "# - Extract the rank of pj. \n",
    "get_rank = lambda pj: [p['rank'] for p in graph if p['node'] == pj][0]\n",
    "\n",
    "# - Calculate pagerank of node pi.\n",
    "_r = lambda pi: ( \n",
    "    d * (\n",
    "        np.sum( [ get_rank(pj) / out_len(pj) for pj in pi['in'] ] ) + \n",
    "        np.sum( [ get_rank(pj['node']) / N for pj in graph if out_len(pj['node']) == 0 ] )\n",
    "    ) + (t / N) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Berechnungen in Iterationen**\n",
    "\n",
    "Die Berechnung erfolgt so lange bis die Abbruchbedingung erfüllt ist.\n",
    "\n",
    "Es gilt folgende Abbruchbedingung:\n",
    "\n",
    "$$\n",
    "\\left(\\sum \\left(| r^{(i)} -r'^{(i)}|\\right) >= \\delta\\right);\\,\\,\\,\\, \\forall r, r' \\in g\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - The iterations of the pageranks\n",
    "while not np.sum( [ abs(g['rank'] - g['rank_']) for g in graph ] ) < delta :\n",
    "    for node in graph:\n",
    "        node['rank_'], node['rank'] = node['rank'], _r(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ausgabe der errechneten Daten**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node\n",
      "d01    0.121327\n",
      "d06    0.143281\n",
      "d08    0.008755\n",
      "d04    0.220873\n",
      "d03    0.128147\n",
      "d02    0.128602\n",
      "d07    0.143407\n",
      "d05    0.120725\n",
      "Name: rank, dtype: float64\n",
      "Σ ----------------\n",
      "1.0151158974735404\n"
     ]
    }
   ],
   "source": [
    "# - Put the calcuated data inside a DataFrame.\n",
    "df = pd.DataFrame(graph)\n",
    "df.index = df['node']\n",
    "# ... writing it to file ...\n",
    "df[['node', 'rank']].to_csv('rank.txt', index=False)\n",
    "# ... and do some printing.\n",
    "pprint(df['rank'])\n",
    "print(\"Σ ----------------\")\n",
    "pprint(np.sum(df['rank']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Aufbau eines inversed Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenizing**\n",
    "\n",
    "Folgende Arbeitsschritte wurden hier abgearbeitet:\n",
    "\n",
    "1. Entfernen aller Sonderzeichen\n",
    "1. Alle großgeschriebenen Buchstaben werden durch ihre kleingeschriebenen ersetzt\n",
    "1. Entfernen aller als Stopwörter definierten Terme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Extracting stopwords from file \n",
    "with open('./stop_words.txt') as infile:\n",
    "    lines = infile.readlines()\n",
    "stopwords = [word.strip(\"'\").strip() \n",
    "             for line in lines \n",
    "             for word in line.split(', ') \n",
    "             if word.strip(\"'\").strip() != '']\n",
    "\n",
    "tokenize = lambda d: [re.compile('[\\W_]+').sub('', w.lower()) for w in d.split() if w not in stopwords]\n",
    "docs = [{'title': d['title'], 'words': tokenize(d['text'])} for d in data ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Indexing**\n",
    "\n",
    "Es wird ein inversed Index aufgebaut.\n",
    "\n",
    "Dabei werden die absoluten Vorkommen der Therme $w$ in den jeweiligen Dokumenten $d$ gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d01</th>\n",
       "      <th>d02</th>\n",
       "      <th>d03</th>\n",
       "      <th>d04</th>\n",
       "      <th>d05</th>\n",
       "      <th>d06</th>\n",
       "      <th>d07</th>\n",
       "      <th>d08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>given</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>defined</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenization</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chopping</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              d01  d02  d03  d04  d05  d06  d07  d08\n",
       "given           1    0    0    0    0    1    0    0\n",
       "character       1    1    0    0    0    0    0    0\n",
       "sequence        1    0    0    0    0    0    0    0\n",
       "defined         1    0    0    0    0    0    0    0\n",
       "document        1    0    0    1    0    1    0    0\n",
       "unit            1    0    0    0    0    0    0    0\n",
       "tokenization    1    0    0    0    0    0    0    0\n",
       "task            1    0    0    0    0    0    0    0\n",
       "chopping        1    0    0    0    0    0    0    0\n",
       "up              1    0    0    0    0    0    0    0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [word for doc in docs for word in doc['words']]\n",
    "\n",
    "iindx = pd.DataFrame.from_dict({ doc['title']: [ \n",
    "    doc['words'].count(word) for word in words ]\n",
    "    for doc in docs })\n",
    "iindx.index = words\n",
    "\n",
    "iindx = iindx[~iindx.index.duplicated(keep='first')]\n",
    "iindx.to_csv('index.txt')\n",
    "iindx.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring und Suche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  e)  TF - IDF\n",
    "\n",
    "**Term Freqency**\n",
    "\n",
    "Hier wurde sich für eine logarithmisch normierte Term Freqency entschieden.\n",
    "\n",
    "Damit gilt:\n",
    "\n",
    "$$\n",
    "\\mbox{log_freq}(w, d) =\n",
    "   \\begin{cases}\n",
    "     1 + log10 tf(w,d) & \\mbox{für}\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, tf(w,d) > 0  \\\\\n",
    "     0 & \\mbox{sonst} \\\\\n",
    "   \\end{cases}\n",
    "$$\n",
    "\n",
    "bei $tf(w,d) := $ absolutes Vorkommen des Terms $w$ in Dokument $d$. \n",
    "\n",
    "*Die Term Frequency steht bereits im Index und muss nur ausgelesen werden.*\n",
    "\n",
    "\n",
    "** Inversed Document Frequency**\n",
    "\n",
    "Ist definiert als \n",
    "$$\\frac{\\mbox{Anzahl der Dokumente}  (N)}{\\mbox{Anzahl der Dokumente welche Term w enthalten }(df(w))  }$$\n",
    "\n",
    "Eine Normierung erfolgt mit $\\log_{10} df(w)$\n",
    "\n",
    "**Scoring und Suchfunktion**\n",
    "\n",
    "Das scoring der Dokumente eines spezifischen Terms kann über die Funktion ```search(words)``` ermittelt werden.\n",
    "\n",
    "Dabei ist es auch möglich, Listen von Termen anzugeben. Diese werden über $A \\land B$ verbunden.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.read_csv('./index.txt', index_col=0)\n",
    "\n",
    "def log_freq(word, doc):\n",
    "    tf = int(idx[doc].loc[word])   \n",
    "    return 1+log(tf, 10) if tf > 0 else 0\n",
    "    \n",
    "def idf(word):\n",
    "    N = idx.shape[0]\n",
    "    df = np.sum(idx.loc[word].map(lambda x: 0 if x == 0 else 1))\n",
    "    return log (  (N / df), 10)\n",
    "\n",
    "tfidf = lambda w,d : (log_freq(w, d) * idf(w))\n",
    "weights = lambda w : [ {d: tfidf(w,d)} \n",
    "    for d in idx.columns.values.tolist() ]\n",
    "\n",
    "pd.DataFrame.from_dict([{word: weights(word) for word in words}])\n",
    "\n",
    "tfiidx = pd.DataFrame.from_dict({ doc['title']: [ \n",
    "    tfidf(word, doc['title']) for word in words ]\n",
    "    for doc in docs })\n",
    "tfiidx.index = words\n",
    "tfiidx = tfiidx[~tfiidx.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search (words):\n",
    "    assert type(words) == list\n",
    "    # - The weights are calculatet by \n",
    "\n",
    "    return pd.DataFrame([tfiidx.loc[w] for w in words]).product()\n",
    "    \n",
    "s_terms = [['tokens'], ['index'], ['classification'], ['tokens', 'classification']]\n",
    "\n",
    "search_df = pd.DataFrame([search(t) for t in s_terms])\n",
    "search_df.index=[' AND '.join(s) for s in s_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d01</th>\n",
       "      <th>d02</th>\n",
       "      <th>d03</th>\n",
       "      <th>d04</th>\n",
       "      <th>d05</th>\n",
       "      <th>d06</th>\n",
       "      <th>d07</th>\n",
       "      <th>d08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>1.342423</td>\n",
       "      <td>1.746532</td>\n",
       "      <td>1.342423</td>\n",
       "      <td>1.746532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.150642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.564271</td>\n",
       "      <td>2.035164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.506057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.564271</td>\n",
       "      <td>1.564271</td>\n",
       "      <td>2.506057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens AND classification</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.389630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                d01       d02       d03       d04       d05  \\\n",
       "tokens                     1.342423  1.746532  1.342423  1.746532  0.000000   \n",
       "index                      0.000000  0.000000  0.000000  1.564271  2.035164   \n",
       "classification             0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "tokens AND classification  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                d06       d07       d08  \n",
       "tokens                     0.000000  0.000000  2.150642  \n",
       "index                      0.000000  0.000000  2.506057  \n",
       "classification             1.564271  1.564271  2.506057  \n",
       "tokens AND classification  0.000000  0.000000  5.389630  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_df.to_csv('tfidf_search.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f) Scoring tfidf und pagerank\n",
    "\n",
    "\n",
    "Um tfidf und pagerank in einem Wert zu vereinen, werden diese über eine Multiplikation zusammengebracht.\n",
    "\n",
    "\n",
    "$$\\mbox{score} = \\mbox{tf_idf}(w, d) \\cdot \\mbox{rank}(d)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>node</th>\n",
       "      <th>d01</th>\n",
       "      <th>d06</th>\n",
       "      <th>d08</th>\n",
       "      <th>d04</th>\n",
       "      <th>d03</th>\n",
       "      <th>d02</th>\n",
       "      <th>d07</th>\n",
       "      <th>d05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>0.162872</td>\n",
       "      <td>0.250245</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.385762</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345506</td>\n",
       "      <td>0.2608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.201168</td>\n",
       "      <td>0.224327</td>\n",
       "      <td>0.302543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens AND classification</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "node                            d01       d06       d08       d04     d03  \\\n",
       "tokens                     0.162872  0.250245  0.011753  0.385762  0.0000   \n",
       "index                      0.000000  0.000000  0.000000  0.345506  0.2608   \n",
       "classification             0.000000  0.000000  0.000000  0.000000  0.0000   \n",
       "tokens AND classification  0.000000  0.000000  0.000000  0.000000  0.0000   \n",
       "\n",
       "node                            d02       d07       d05  \n",
       "tokens                     0.000000  0.000000  0.259636  \n",
       "index                      0.000000  0.000000  0.302543  \n",
       "classification             0.201168  0.224327  0.302543  \n",
       "tokens AND classification  0.000000  0.000000  0.650662  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = pd.read_csv('rank.txt', index_col=0)\n",
    "s = pd.read_csv('tfidf_search.txt', index_col=0)\n",
    "\n",
    "score = pd.DataFrame(r.values * s.T.values, index=r.index, columns=s.index).T\n",
    "score.to_csv('pageranke_search.txt')\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
