{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Engine\n",
    "\n",
    "\n",
    "Zweite Belegaufgabe aus dem Fach Contentmanagement / Text- und Suchtechnologien (WT-2) an der HTW Berlin bei Herrn Prof. Dr. Zhang.\n",
    "\n",
    "\n",
    "- *Sebastian Schmid s0543196)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " graded02.pdf\t  my_spider.py\t\t stop_words.txt\r\n",
      " index.txt\t  pageranke_search.txt\t tfidf_search.txt\r\n",
      " my_spider.json   __pycache__\t\t'WT-2 zweite Belegaufgabe.ipynb'\r\n",
      " my_spider.log\t  rank.txt\r\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "import re \n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "#IFrame(\"./graded02.pdf\", width=900, height=1400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a ) Der Crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./my_spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./my_spider.py\n",
    "# %%writefile ./my_spider.py\n",
    "# %load ./my_spider.py\n",
    "\n",
    "import scrapy\n",
    "import json\n",
    "\n",
    "class HtwSpider(scrapy.Spider):\n",
    "    name = 'htw_spider'\n",
    "    \n",
    "    start_urls = [\n",
    "        'http://people.f4.htw-berlin.de/~zhangg/pages/teaching/pages/d01.html',\n",
    "        'http://people.f4.htw-berlin.de/~zhangg/pages/teaching/pages/d06.html',\n",
    "        'http://people.f4.htw-berlin.de/~zhangg/pages/teaching/pages/d08.html'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "         \n",
    "        # - Extracting the needed attributes.\n",
    "        title = response.xpath('//title/text()').extract()[0]\n",
    "        text = ' '.join([t.strip() for t in response.xpath('//body/text()').extract()]).strip()\n",
    "        hrefs =  [l.split('.')[0] for l in response.xpath('//a/@href').extract()]\n",
    "                      \n",
    "        # - Printing the extracted data for logging. \n",
    "        print(\"\\n ----DATA\\n\\n%s\\n\" % json.dumps({title : {'text': text, \n",
    "                        'refs' : hrefs }}))\n",
    "        \n",
    "        # - Yielding the extracted dataset as dict\n",
    "        yield {'title': title,\n",
    "               'text': text, \n",
    "               'refs' : hrefs }\n",
    "        # - Here we find the actual spider.\n",
    "        # - This goes through all a_hrefs and scrape the needed data.\n",
    "        for next_page in response.xpath('//a/@href').extract():\n",
    "            if next_page is None:\n",
    "                continue\n",
    "            next_page = response.urljoin(next_page)\n",
    "            yield scrapy.Request(next_page, callback=self.parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - Here we call the scrapy process.\n",
    "# \n",
    "# - This is needed to call this inside the notebook.\n",
    "# - Scrapy concatenates all outputs (with destroying the json)\n",
    "#   so we need to remove it first.\n",
    "\n",
    "#   !!Attention!!   This will execute rm (!) on the the OS.  \n",
    "#                   Won't work on windows.\n",
    "!rm ./my_spider.json\n",
    "\n",
    "# - Executing the spider.\n",
    "pout = check_output('scrapy runspider my_spider.py -o my_spider.json', shell=True)\n",
    "# - Writing the output into logfile.\n",
    "with open('./my_spider.log', 'w') as logfile:\n",
    "    logfile.write(pout.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the crawled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>refs</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d01</th>\n",
       "      <td>[d02, d03, d04]</td>\n",
       "      <td>Given a character sequence and a defined docum...</td>\n",
       "      <td>d01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d06</th>\n",
       "      <td>[d07]</td>\n",
       "      <td>In text classification, we are given a descrip...</td>\n",
       "      <td>d06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d08</th>\n",
       "      <td>[]</td>\n",
       "      <td>s is a spam page. tokens stopwords index posti...</td>\n",
       "      <td>d08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d04</th>\n",
       "      <td>[d01, d02, d03, d05]</td>\n",
       "      <td>To gain the speed benefits of indexing at retr...</td>\n",
       "      <td>d04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d02</th>\n",
       "      <td>[d03, d04, d01, d05]</td>\n",
       "      <td>Token normalization is the process of canonica...</td>\n",
       "      <td>d02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d03</th>\n",
       "      <td>[d04, d01, d02, d05]</td>\n",
       "      <td>For English, an alternative to making every to...</td>\n",
       "      <td>d03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d07</th>\n",
       "      <td>[d06]</td>\n",
       "      <td>Using a supervised learning method or learning...</td>\n",
       "      <td>d07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d05</th>\n",
       "      <td>[d04]</td>\n",
       "      <td>Index the documents that each term occurs in b...</td>\n",
       "      <td>d05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       refs  \\\n",
       "title                         \n",
       "d01         [d02, d03, d04]   \n",
       "d06                   [d07]   \n",
       "d08                      []   \n",
       "d04    [d01, d02, d03, d05]   \n",
       "d02    [d03, d04, d01, d05]   \n",
       "d03    [d04, d01, d02, d05]   \n",
       "d07                   [d06]   \n",
       "d05                   [d04]   \n",
       "\n",
       "                                                    text title  \n",
       "title                                                           \n",
       "d01    Given a character sequence and a defined docum...   d01  \n",
       "d06    In text classification, we are given a descrip...   d06  \n",
       "d08    s is a spam page. tokens stopwords index posti...   d08  \n",
       "d04    To gain the speed benefits of indexing at retr...   d04  \n",
       "d02    Token normalization is the process of canonica...   d02  \n",
       "d03    For English, an alternative to making every to...   d03  \n",
       "d07    Using a supervised learning method or learning...   d07  \n",
       "d05    Index the documents that each term occurs in b...   d05  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - Reading the Data from json into python obj-structure.-\n",
    "with open('./my_spider.json') as infile:\n",
    "    data = json.loads(''.join([line.strip() for line in infile.readlines()]))   \n",
    "    \n",
    "# - Removing all duplicates\n",
    "data = list({d['title']:d for d in data}.values())\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df.index = df['title']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)  Page Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "r_{k+1}(p_i) = d \\cdot \\left( \\sum_{pj \\in B_{p_i}}   \\frac{r_k(pj)}{|pj|}  + \\sum_{pj,\\,|pj|=0}  \\frac{r_k(p_j)}{N} \\right) + \\frac{t}{N}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in</th>\n",
       "      <th>node</th>\n",
       "      <th>out</th>\n",
       "      <th>rank</th>\n",
       "      <th>rank_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[d04, d02, d03]</td>\n",
       "      <td>d01</td>\n",
       "      <td>[d02, d03, d04]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[d07]</td>\n",
       "      <td>d06</td>\n",
       "      <td>[d07]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>d08</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[d01, d02, d03, d05]</td>\n",
       "      <td>d04</td>\n",
       "      <td>[d01, d02, d03, d05]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[d01, d04, d03]</td>\n",
       "      <td>d02</td>\n",
       "      <td>[d03, d04, d01, d05]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[d01, d04, d02]</td>\n",
       "      <td>d03</td>\n",
       "      <td>[d04, d01, d02, d05]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[d06]</td>\n",
       "      <td>d07</td>\n",
       "      <td>[d06]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[d04, d02, d03]</td>\n",
       "      <td>d05</td>\n",
       "      <td>[d04]</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     in node                   out   rank  rank_\n",
       "0       [d04, d02, d03]  d01       [d02, d03, d04]  0.125   1.04\n",
       "1                 [d07]  d06                 [d07]  0.125   1.04\n",
       "2                    []  d08                    []  0.125   1.04\n",
       "3  [d01, d02, d03, d05]  d04  [d01, d02, d03, d05]  0.125   1.04\n",
       "4       [d01, d04, d03]  d02  [d03, d04, d01, d05]  0.125   1.04\n",
       "5       [d01, d04, d02]  d03  [d04, d01, d02, d05]  0.125   1.04\n",
       "6                 [d06]  d07                 [d06]  0.125   1.04\n",
       "7       [d04, d02, d03]  d05                 [d04]  0.125   1.04"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = 0.04 \n",
    "N = len(data)\n",
    "t = 0.05\n",
    "d = 1-t\n",
    "\n",
    "graph = [ {\n",
    "    'node': d['title'], \n",
    "    'out':  d['refs'], \n",
    "    'in' : [n['title'] for n in data if d['title'] in n['refs']],\n",
    "    'rank': 1.0 / N,          # (1 / n) \\leq 1 \\forall n \\in \\mathbb{N}\n",
    "    'rank_': 1.0 + delta      # mocking rank_ \n",
    "} for d in data ]\n",
    "\n",
    "pd.DataFrame.from_dict(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node\n",
      "d01    0.121327\n",
      "d06    0.143281\n",
      "d08    0.008755\n",
      "d04    0.220873\n",
      "d02    0.128147\n",
      "d03    0.128602\n",
      "d07    0.143407\n",
      "d05    0.120725\n",
      "Name: rank, dtype: float64\n",
      "+ ----------------\n",
      "1.0151158974735404\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Calculating the rank.\"\"\"\n",
    "\n",
    "# - Functions to calc the rank\n",
    "abs_pj = lambda pj: [len(page['out']) for page in graph if page['node'] == pj][0]\n",
    "get_rank = lambda pj: [p['rank'] for p in graph if p['node'] == pj][0]\n",
    "\n",
    "_r = lambda pi: ( \n",
    "    d * (\n",
    "        np.sum( [ get_rank(pj) / abs_pj(pj) for pj in pi['in'] ] ) + \n",
    "        np.sum( [ get_rank(pj['node']) / N for pj in graph if abs_pj(pj['node']) == 0 ])\n",
    "    ) + (t / N) )\n",
    "\n",
    "# - The iterations of the pageranks\n",
    "while not np.sum([abs(g['rank'] - g['rank_']) for g in graph]) < delta :\n",
    "    for node in graph:\n",
    "        node['rank_'], node['rank'] = node['rank'], _r(node)\n",
    "\n",
    "# - Put the calcuated data inside a DataFrame\n",
    "df = pd.DataFrame(graph)\n",
    "df.index = df['node']\n",
    "# - Writing to file\n",
    "df[['node', 'rank']].to_csv('rank.txt', index=False)\n",
    "pprint(df['rank'])\n",
    "print(\"+ ----------------\")\n",
    "pprint(np.sum(df['rank']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in</th>\n",
       "      <th>node</th>\n",
       "      <th>out</th>\n",
       "      <th>rank</th>\n",
       "      <th>rank_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[d04, d02, d03]</td>\n",
       "      <td>d01</td>\n",
       "      <td>[d02, d03, d04]</td>\n",
       "      <td>0.121327</td>\n",
       "      <td>0.110156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[d07]</td>\n",
       "      <td>d06</td>\n",
       "      <td>[d07]</td>\n",
       "      <td>0.143281</td>\n",
       "      <td>0.139844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>d08</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>0.021094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[d01, d02, d03, d05]</td>\n",
       "      <td>d04</td>\n",
       "      <td>[d01, d02, d03, d05]</td>\n",
       "      <td>0.220873</td>\n",
       "      <td>0.221763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[d01, d04, d03]</td>\n",
       "      <td>d02</td>\n",
       "      <td>[d03, d04, d01, d05]</td>\n",
       "      <td>0.128147</td>\n",
       "      <td>0.125994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[d01, d04, d02]</td>\n",
       "      <td>d03</td>\n",
       "      <td>[d04, d01, d02, d05]</td>\n",
       "      <td>0.128602</td>\n",
       "      <td>0.126230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[d06]</td>\n",
       "      <td>d07</td>\n",
       "      <td>[d06]</td>\n",
       "      <td>0.143407</td>\n",
       "      <td>0.141606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[d04, d02, d03]</td>\n",
       "      <td>d05</td>\n",
       "      <td>[d04]</td>\n",
       "      <td>0.120725</td>\n",
       "      <td>0.121327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     in node                   out      rank     rank_\n",
       "0       [d04, d02, d03]  d01       [d02, d03, d04]  0.121327  0.110156\n",
       "1                 [d07]  d06                 [d07]  0.143281  0.139844\n",
       "2                    []  d08                    []  0.008755  0.021094\n",
       "3  [d01, d02, d03, d05]  d04  [d01, d02, d03, d05]  0.220873  0.221763\n",
       "4       [d01, d04, d03]  d02  [d03, d04, d01, d05]  0.128147  0.125994\n",
       "5       [d01, d04, d02]  d03  [d04, d01, d02, d05]  0.128602  0.126230\n",
       "6                 [d06]  d07                 [d06]  0.143407  0.141606\n",
       "7       [d04, d02, d03]  d05                 [d04]  0.120725  0.121327"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./stop_words.txt') as infile:\n",
    "    lines = infile.readlines()\n",
    "stopwords = [word.strip(\"'\").strip() \n",
    "             for line in lines for word \n",
    "             in line.split(', ') \n",
    "             if word.strip(\"'\").strip() != '']\n",
    "\n",
    "pattern = re.compile('[\\W_]+')  \n",
    "\n",
    "tokenizer = lambda d: [pattern.sub('', w.lower()) for w in d.split() if w not in stopwords]\n",
    "\n",
    "docs = [{'title': d['title'], 'words': tokenizer(d['text'])} for d in data ]\n",
    "#docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d01</th>\n",
       "      <th>d02</th>\n",
       "      <th>d03</th>\n",
       "      <th>d04</th>\n",
       "      <th>d05</th>\n",
       "      <th>d06</th>\n",
       "      <th>d07</th>\n",
       "      <th>d08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>given</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>defined</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           d01  d02  d03  d04  d05  d06  d07  d08\n",
       "given        1    0    0    0    0    1    0    0\n",
       "character    1    1    0    0    0    0    0    0\n",
       "sequence     1    0    0    0    0    0    0    0\n",
       "defined      1    0    0    0    0    0    0    0\n",
       "document     1    0    0    1    0    1    0    0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [word for doc in docs for word in doc['words']]\n",
    "\n",
    "iindx = pd.DataFrame.from_dict({ doc['title']: [ \n",
    "    doc['words'].count(word) for word in words ]\n",
    "    for doc in docs })\n",
    "iindx.index = words\n",
    "\n",
    "iindx = iindx[~iindx.index.duplicated(keep='first')]\n",
    "iindx.to_csv('index.txt')\n",
    "iindx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  e)  TF - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = pd.read_csv('./index.txt', index_col=0)\n",
    "\n",
    "def df(word, doc):\n",
    "    f = int(idx[doc].loc[word])   \n",
    "    return 1+log(f) if f > 0 else 0\n",
    "    \n",
    "def idf(word):\n",
    "    N = idx.shape[0]\n",
    "    n_i = np.sum(idx.loc[word].map(lambda x: 0 if x == 0 else 1))\n",
    "    \n",
    "    return log (N / n_i)\n",
    "\n",
    "tfidf = lambda w, d: (df(w, d) * idf(w))\n",
    "weights = lambda w : [{d: tfidf(w,d)} for d in idx.columns.values.tolist()]\n",
    "pd.DataFrame.from_dict([{word: weights(word) for word in words}])\n",
    "\n",
    "tfiidx = pd.DataFrame.from_dict({ doc['title']: [ \n",
    "    tfidf(word, doc['title']) for word in words ]\n",
    "    for doc in docs })\n",
    "tfiidx.index = words\n",
    "tfiidx = tfiidx[~tfiidx.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search (words):\n",
    "    assert type(words) == list\n",
    "    \n",
    "    return pd.DataFrame([tfiidx.loc[w] for w in words]).product()\n",
    "    \n",
    "s_terms = [['tokens'], ['index'], ['classification'], ['tokens', 'classification']]\n",
    "\n",
    "search_df = pd.DataFrame([search(t) for t in s_terms])\n",
    "search_df.index=[' AND '.join(s) for s in s_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d01</th>\n",
       "      <th>d02</th>\n",
       "      <th>d03</th>\n",
       "      <th>d04</th>\n",
       "      <th>d05</th>\n",
       "      <th>d06</th>\n",
       "      <th>d07</th>\n",
       "      <th>d08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>3.091042</td>\n",
       "      <td>5.23359</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>5.233590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.376137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.601868</td>\n",
       "      <td>6.098493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.595117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.601868</td>\n",
       "      <td>3.601868</td>\n",
       "      <td>8.595117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens AND classification</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.398766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                d01      d02       d03       d04       d05  \\\n",
       "tokens                     3.091042  5.23359  3.091042  5.233590  0.000000   \n",
       "index                      0.000000  0.00000  0.000000  3.601868  6.098493   \n",
       "classification             0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "tokens AND classification  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                d06       d07        d08  \n",
       "tokens                     0.000000  0.000000   7.376137  \n",
       "index                      0.000000  0.000000   8.595117  \n",
       "classification             3.601868  3.601868   8.595117  \n",
       "tokens AND classification  0.000000  0.000000  63.398766  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_df.to_csv('tfidf_search.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f) Scoring tfidf und pagerank\n",
    "\n",
    "$$\\mbox{score} = \\mbox{tf_idf}(w, d) \\cdot \\mbox{rank}(d)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>node</th>\n",
       "      <th>d01</th>\n",
       "      <th>d06</th>\n",
       "      <th>d08</th>\n",
       "      <th>d04</th>\n",
       "      <th>d02</th>\n",
       "      <th>d03</th>\n",
       "      <th>d07</th>\n",
       "      <th>d05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>0.375026</td>\n",
       "      <td>0.749874</td>\n",
       "      <td>0.027062</td>\n",
       "      <td>1.155960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.890483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795556</td>\n",
       "      <td>0.781502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.037644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.463207</td>\n",
       "      <td>0.516532</td>\n",
       "      <td>1.037644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens AND classification</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.653806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "node                            d01       d06       d08       d04       d02  \\\n",
       "tokens                     0.375026  0.749874  0.027062  1.155960  0.000000   \n",
       "index                      0.000000  0.000000  0.000000  0.795556  0.781502   \n",
       "classification             0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "tokens AND classification  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "node                            d03       d07       d05  \n",
       "tokens                     0.000000  0.000000  0.890483  \n",
       "index                      0.000000  0.000000  1.037644  \n",
       "classification             0.463207  0.516532  1.037644  \n",
       "tokens AND classification  0.000000  0.000000  7.653806  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = pd.read_csv('rank.txt', index_col=0)\n",
    "s = pd.read_csv('tfidf_search.txt', index_col=0)\n",
    "\n",
    "score = pd.DataFrame(r.values * s.T.values, index=r.index, columns=s.index).T\n",
    "score.to_csv('pageranke_search.txt')\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
